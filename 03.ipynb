{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c9f38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu126\n",
      "torchvision version: 0.23.0+cu126\n"
     ]
    }
   ],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Import torchvision \n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check versions\n",
    "# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9253e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training data\n",
    "train_data = datasets.MNIST(\n",
    "    root=\"data\", # where to download data to?\n",
    "    train=True, # get training data\n",
    "    download=True, # download data if it doesn't exist on disk\n",
    "    transform=ToTensor(), # images come as PIL format, we want to turn into Torch tensors\n",
    "    target_transform=None # you can transform labels as well\n",
    ")\n",
    "\n",
    "# Setup testing data\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False, # get test data\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a057ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7ee8536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd372be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 60000, 10000, 10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many samples are there? \n",
    "len(train_data.data), len(train_data.targets), len(test_data.data), len(test_data.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8660fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 - zero',\n",
       " '1 - one',\n",
       " '2 - two',\n",
       " '3 - three',\n",
       " '4 - four',\n",
       " '5 - five',\n",
       " '6 - six',\n",
       " '7 - seven',\n",
       " '8 - eight',\n",
       " '9 - nine']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See classes\n",
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "003a8838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image, label = train_data[0]\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "plt.imshow(image.squeeze()) # image shape is [1, 28, 28] (colour channels, height, width)\n",
    "plt.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1e1f18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x900 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot more images\n",
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3a5de4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x00000247EAB74D60>, <torch.utils.data.dataloader.DataLoader object at 0x00000247EA71BAF0>)\n",
      "Length of train dataloader: 1875 batches of 32\n",
      "Length of test dataloader: 313 batches of 32\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(train_data, # dataset to turn into iterable\n",
    "    batch_size=BATCH_SIZE, # how many samples per batch? \n",
    "    shuffle=True # shuffle data every epoch?\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False # don't necessarily have to shuffle the testing data\n",
    ")\n",
    "\n",
    "# Let's check out what we've created\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3f17000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out what's inside the training dataloader\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c407628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: torch.Size([1, 28, 28])\n",
      "Label: 9, label size: torch.Size([])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAADRxJREFUeJzt3F1ol3Ufx/Hvv01TmZoNozIts61OPAg70FYZZMswQkUkkMyKSiJIysI6yIccEWoPB3kghAk9EFkhBXaQSHWQrOe0kpQSJKTIlNRMSa/7pPsLu9Xu/f45t+z1Ag82rg/XT7C9u9y8alVVVQEAEXFGbx8AgL5DFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFKAbarVaLFq0qLePAT1OFOhzPvnkk5g8eXIMGTIkBg8eHO3t7fH555/39rHgX6Hm3Uf0JZ9++mm0tbXFyJEj45577omjR4/GypUr45dffonOzs649NJLe+Vcv//+ezQ2NkZjY2Ov3B9OFVGgT5kyZUp8+OGHsW3btmhubo6IiF27dkVra2u0t7fH66+/3ssnhNObvz6iT/nggw9i0qRJGYSIiPPOOy8mTpwYb7/9duzfv/+k3WvOnDnR1NQUP/zwQ0ydOjWamppi+PDhMX/+/Dhy5EiXa//3ewqLFi2KWq0W27dvjzlz5sRZZ50VQ4cOjdtvvz1+++23Y+714osvxrhx42LgwIFx9tlnxy233BI7d+48ab8XOFlEgT7l0KFDMXDgwGM+P2jQoDh8+HBs2bLlpN7vyJEjccMNN0Rzc3MsX748Jk6cGCtWrIhVq1Z1az9z5szYt29fPPHEEzFz5sx44YUXYvHixV2u6ejoiNmzZ0dLS0s89dRTMW/evNiwYUNcc801sXfv3pP6+4G/rYI+ZOzYsVVra2v1xx9/5OcOHTpUjRo1qoqIau3atSftXrfddlsVEdWSJUu6fP7yyy+vxo0b1+VzEVEtXLgwP164cGEVEdUdd9zR5bpp06ZVzc3N+fGOHTuqhoaGqqOjo8t1mzdvrhobG4/5PPQ2Twr0Kffee298++23ceedd8bXX38dW7ZsidmzZ8euXbsiIuLgwYMn/Z5z587t8vHVV18d3333Xd3b3bt3x6+//hoREW+88UYcPXo0Zs6cGT///HP+Ovfcc6OlpSU2btx4cn4TcJL4UQr6lLlz58bOnTtj2bJlsWbNmoiIuOKKK+Lhhx+Ojo6OaGpqOuF2//79Xb7n0NDQEMOHD//L+w0YMOCYa4YNGxZ79uzp1nlHjRp1zDYiYs+ePTFkyJDYtm1bVFUVLS0tx93369evW/eBU0UU6HM6Ojpi/vz58dVXX8XQoUNj7Nix8eijj0ZERGtr6wl3y5cv7/L3+RdeeGHs2LHjL+/V0NDwt856on315w/1HT16NGq1Wqxfv/641/5V5KA3iAJ90rBhw+Kqq67Kj99999244IIL4rLLLjvhZvbs2V02x/uG9ak2ZsyYqKoqRo8e/ZdBg77C9xTo81599dX46KOPYt68eXHGGSf+I3vxxRfHpEmT8ldbW9spPOXxTZ8+PRoaGmLx4sX59PBfVVXF7t27e+lkcHyeFOhT3n///ViyZEm0t7dHc3NzbNq0KVavXh2TJ0+O+++/v7ePV2zMmDGxdOnSeOSRR2LHjh0xderUGDx4cHz//ffx5ptvxt133x3z58/v7WNCEgX6lBEjRkRDQ0MsW7Ys9u3bF6NHj46lS5fGAw888I99xcSCBQuitbU1nn766fyex8iRI6O9vT1uvvnmXj4ddOU1FwAk31MAIIkCAEkUAEiiAEASBQCSKACQuv2D37VarSfPAUAP686/QPCkAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIDX29gGgJzQ0NBRv2traijczZswo3lx55ZXFm4iIcePG1bUrtXXr1uLNunXrijcLFiwo3tDzPCkAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACB5IR593iWXXFK8WbNmTfFmwoQJxZt6HDp0qK7dxx9/XLxZu3Zt8ebLL78s3mzbtq14Q9/kSQGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEjekkpd+vXrV7yZMWNGXfdavXp18aZ///7Fm7179xZvnnzyyeLNunXrijcREVu3bq1rByU8KQCQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIHkhHnWZPn168eall17qgZMc3+bNm4s37e3txZsff/yxeAN9mScFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkL8QjzjzzzOLNrFmzeuAkx9fZ2Vm8mTJlSvFm9+7dxRs43XhSACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBA8kI8YsyYMcWbm266qQdOcnwbN24s3ni5HdTHkwIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBqVVVV3bqwVuvps9BL+vfvX7x55ZVXijfTpk0r3kREHDx4sHjzxRdfFG9ee+214s2IESOKN938T+4YAwYMKN60tLQUb5555pnizTvvvFO84dTrzp89TwoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiNvX0Aet/hw4eLN/PmzSve/PTTT8WbiIgpU6YUb8aPH39KNqejzs7O4o0X4p0+PCkAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACDVqqqqunVhrdbTZ4HjGjRoUPFm1KhRxZsJEyYUb844o/z/q9ra2oo3ERFz5swp3hw4cKB4M3Xq1OLNhg0bijecet35cu9JAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIAyQvx4G+46KKLijfvvfdeXfcaOXJk8eahhx4q3qxYsaJ4wz+DF+IBUEQUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQBSY28fAP7JZs2aVbyp58V2EREHDhwo3qxbt66ue/Hv5UkBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABI3pIKf7r22muLN48//vjJP8gJrFq1qnizffv2HjgJpzNPCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASF6IB3+67777ije1Wq14s2nTpuJNRMTSpUvr2kEJTwoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEi1qqqqbl1Yx4u/oLdcf/31xZv169cXb/bv31+8GT9+fPEmImLr1q117eC/uvPl3pMCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQBSY28fAP6f6667rnjz8ssvF2/qebndokWLijdebEdf5kkBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgCpVlVV1a0La7WePgunuaamprp269evL960tbUVb55//vnizV133VW8gd7SnS/3nhQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYDU2NsH4N9j1qxZde3qeePpN998U7x58MEHizdwuvGkAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAVKuqqurWhbVaT5+Ff5Bbb721eLNy5cq67nX48OHizY033li86ezsLN7AP0l3vtx7UgAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQPJCPOL8888v3nz22WfFm8bGxuJNRMRjjz1WvHnuuefquheczrwQD4AiogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkOp7Qxl91jnnnFO8eeutt4o3w4cPL948++yzxZsIL7eDU8mTAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkGpVVVXdurBW6+mzANCDuvPl3pMCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAKmxuxdWVdWT5wCgD/CkAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAED6D5Aq+vF8JHQ7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a sample\n",
    "torch.manual_seed(42)\n",
    "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(class_names[label])\n",
    "plt.axis(\"Off\");\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"Label: {label}, label size: {label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83a861dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before flattening: torch.Size([1, 28, 28]) -> [color_channels, height, width]\n",
      "Shape after flattening: torch.Size([1, 784]) -> [color_channels, height*width]\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1608, 0.9373, 0.9922, 0.9922, 0.3255, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.6863, 0.9843, 0.9843, 0.9843, 0.9059, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.6863, 0.9843, 0.9843, 0.9843, 0.9059, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745,\n",
      "          0.7294, 0.9843, 0.9843, 0.9843, 0.7882, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902, 0.6588,\n",
      "          0.9843, 0.9843, 0.9843, 0.9843, 0.1451, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2314, 0.9843,\n",
      "          0.9843, 0.9843, 0.9843, 0.6039, 0.0588, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8784, 0.9843,\n",
      "          0.9843, 0.9843, 0.9529, 0.3451, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2392, 0.9922, 0.9843,\n",
      "          0.9843, 0.9843, 0.6000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7608, 0.9922, 0.9843,\n",
      "          0.9843, 0.8980, 0.2784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.4157, 0.9333, 0.9922, 0.9843,\n",
      "          0.9843, 0.2431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.3098, 0.9922, 0.9922, 1.0000, 0.9922,\n",
      "          0.3020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0392, 0.6196, 0.9843, 0.9843, 0.9922, 0.7686,\n",
      "          0.1608, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.6078, 0.9843, 0.9843, 0.9843, 0.8314, 0.1608,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.5647, 0.9725, 0.9843, 0.9843, 0.9843, 0.0549, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1490, 0.7529, 0.9843, 0.9843, 0.9843, 0.6863, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980,\n",
      "          0.7529, 0.9843, 0.9843, 0.9843, 0.6510, 0.0863, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8000,\n",
      "          0.9843, 0.9843, 0.9765, 0.6706, 0.0667, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9137,\n",
      "          0.9843, 0.9843, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3765, 0.9529,\n",
      "          0.9843, 0.6510, 0.0667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6863, 0.9843,\n",
      "          0.9843, 0.3765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.1608, 0.9373, 0.9922, 0.9922, 0.3255, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.6863, 0.9843, 0.9843, 0.9843, 0.9059,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6863, 0.9843, 0.9843, 0.9843,\n",
      "         0.9059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.7294, 0.9843, 0.9843,\n",
      "         0.9843, 0.7882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902, 0.6588, 0.9843, 0.9843,\n",
      "         0.9843, 0.9843, 0.1451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2314, 0.9843, 0.9843,\n",
      "         0.9843, 0.9843, 0.6039, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8784, 0.9843,\n",
      "         0.9843, 0.9843, 0.9529, 0.3451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2392, 0.9922,\n",
      "         0.9843, 0.9843, 0.9843, 0.6000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7608,\n",
      "         0.9922, 0.9843, 0.9843, 0.8980, 0.2784, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4157,\n",
      "         0.9333, 0.9922, 0.9843, 0.9843, 0.2431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3098,\n",
      "         0.9922, 0.9922, 1.0000, 0.9922, 0.3020, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0392,\n",
      "         0.6196, 0.9843, 0.9843, 0.9922, 0.7686, 0.1608, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.6078, 0.9843, 0.9843, 0.9843, 0.8314, 0.1608, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.5647, 0.9725, 0.9843, 0.9843, 0.9843, 0.0549, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1490, 0.7529, 0.9843, 0.9843, 0.9843, 0.6863, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0980, 0.7529, 0.9843, 0.9843, 0.9843, 0.6510, 0.0863, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.8000, 0.9843, 0.9843, 0.9765, 0.6706, 0.0667, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9137, 0.9843, 0.9843, 0.6706, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.3765, 0.9529, 0.9843, 0.6510, 0.0667, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.6863, 0.9843, 0.9843, 0.3765, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Create a flatten layer\n",
    "flatten_model = nn.Flatten() # all nn modules function as a model (can do a forward pass)\n",
    "\n",
    "# Get a single sample\n",
    "x = train_features_batch[0]\n",
    "\n",
    "# Flatten the sample\n",
    "output = flatten_model(x) # perform forward pass\n",
    "\n",
    "# Print out what happened\n",
    "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Shape after flattening: {output.shape} -> [color_channels, height*width]\")\n",
    "\n",
    "# Try uncommenting below and see what happens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a608b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), # neural networks like their inputs in vector form\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units), # in_features = number of features in a data sample (784 pixels)\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b0bf049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModelV0(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Need to setup model with input parameters\n",
    "model_0 = FashionMNISTModelV0(input_shape=784, # one for every pixel (28x28)\n",
    "    hidden_units=10, # how many units in the hidden layer\n",
    "    output_shape=len(class_names) # one for every class\n",
    ")\n",
    "model_0.to(\"cpu\") # keep model on CPU to begin with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29f81fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_functions.py already exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path \n",
    "\n",
    "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "  print(\"helper_functions.py already exists, skipping download\")\n",
    "else:\n",
    "  print(\"Downloading helper_functions.py\")\n",
    "  # Note: you need the \"raw\" GitHub URL for this to work\n",
    "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "  with open(\"helper_functions.py\", \"wb\") as f:\n",
    "    f.write(request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8fb5ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import accuracy metric\n",
    "from helper_functions import accuracy_fn # Note: could also use torchmetrics.Accuracy(task = 'multiclass', num_classes=len(class_names)).to(device)\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss() # this is also called \"criterion\"/\"cost function\" in some places\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26eddf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer \n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \"\"\"Prints difference between start and end time.\n",
    "\n",
    "    Args:\n",
    "        start (float): Start time of computation (preferred in timeit format). \n",
    "        end (float): End time of computation.\n",
    "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        float: time between start and end in seconds (higher is longer).\n",
    "    \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1368bbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\AI\\PyTorch_Tutorial\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:06<00:12,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.85480 | Test loss: 0.42934, Test acc: 88.27%\n",
      "\n",
      "Epoch: 1\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:11<00:05,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.40053 | Test loss: 0.35112, Test acc: 89.84%\n",
      "\n",
      "Epoch: 2\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:18<00:00,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.35146 | Test loss: 0.32292, Test acc: 90.85%\n",
      "\n",
      "Train time on cpu: 18.210 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set the seed and start the timer\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "# Set the number of epochs (we'll keep this small for faster training times)\n",
    "epochs = 3\n",
    "\n",
    "# Create training and testing loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "    ### Training\n",
    "    train_loss = 0\n",
    "    # Add a loop to loop through training batches\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model_0.train() \n",
    "        # 1. Forward pass\n",
    "        y_pred = model_0(X)\n",
    "\n",
    "        # 2. Calculate loss (per batch)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # accumulatively add up the loss per epoch \n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print out how many samples have been seen\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    ### Testing\n",
    "    # Setup variables for accumulatively adding up loss and accuracy \n",
    "    test_loss, test_acc = 0, 0 \n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader:\n",
    "            # 1. Forward pass\n",
    "            test_pred = model_0(X)\n",
    "           \n",
    "            # 2. Calculate loss (accumulatively)\n",
    "            test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
    "\n",
    "            # 3. Calculate accuracy (preds need to be same as y_true)\n",
    "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
    "        \n",
    "        # Calculations on test metrics need to happen inside torch.inference_mode()\n",
    "        # Divide total test loss by length of test dataloader (per batch)\n",
    "        test_loss /= len(test_dataloader)\n",
    "\n",
    "        # Divide total accuracy by length of test dataloader (per batch)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    ## Print out what's happening\n",
    "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
    "\n",
    "# Calculate training time      \n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu, \n",
    "                                           end=train_time_end_on_cpu,\n",
    "                                           device=str(next(model_0.parameters()).device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0788695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV0',\n",
       " 'model_loss': 0.3229216933250427,\n",
       " 'model_acc': 90.85463258785943}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module, \n",
    "               data_loader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               accuracy_fn):\n",
    "    \"\"\"Returns a dictionary containing the results of model predicting on data_loader.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
    "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
    "        loss_fn (torch.nn.Module): The loss function of model.\n",
    "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Results of model making predictions on data_loader.\n",
    "    \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Make predictions with the model\n",
    "            y_pred = model(X)\n",
    "            \n",
    "            # Accumulate the loss and accuracy values per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, \n",
    "                                y_pred=y_pred.argmax(dim=1)) # For accuracy, need the prediction labels (logits -> pred_prob -> pred_labels)\n",
    "        \n",
    "        # Scale loss and acc to find the average loss/acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "        \n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "\n",
    "# Calculate model 0 results on test dataset\n",
    "model_0_results = eval_model(model=model_0, data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn, accuracy_fn=accuracy_fn\n",
    ")\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1b62c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b5a5a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with non-linear and linear layers\n",
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.BatchNorm1d(hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layer_stack(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "636b10a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_1 = FashionMNISTModelV1(input_shape=784, # number of input features\n",
    "    hidden_units=10,\n",
    "    output_shape=len(class_names) # number of output classes desired\n",
    ").to(device) # send model to GPU if it's available\n",
    "next(model_1.parameters()).device # check model device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84703339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(), \n",
    "                            lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa620054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # Send data to GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval() # put model in eval mode\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode(): \n",
    "        for X, y in data_loader:\n",
    "            # Send data to GPU\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "            \n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
    "            )\n",
    "        \n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d82bd065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "---------\n",
      "Train loss: 0.43329 | Train accuracy: 87.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:08<00:16,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.26511 | Test accuracy: 92.14%\n",
      "\n",
      "Epoch: 1\n",
      "---------\n",
      "Train loss: 0.26627 | Train accuracy: 92.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:15<00:07,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.22565 | Test accuracy: 93.35%\n",
      "\n",
      "Epoch: 2\n",
      "---------\n",
      "Train loss: 0.23861 | Train accuracy: 93.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.22198 | Test accuracy: 93.58%\n",
      "\n",
      "Train time on cuda: 24.915 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=train_dataloader, \n",
    "        model=model_1, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn\n",
    "    )\n",
    "    test_step(data_loader=test_dataloader,\n",
    "        model=model_1,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn\n",
    "    )\n",
    "\n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
    "                                            end=train_time_end_on_gpu,\n",
    "                                            device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60d8161d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but got mat1 is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Note: This will error due to `eval_model()` not using device agnostic code \u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model_1_results \u001b[38;5;241m=\u001b[39m \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccuracy_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccuracy_fn\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      8\u001b[0m model_1_results \n",
      "Cell \u001b[1;32mIn[24], line 22\u001b[0m, in \u001b[0;36meval_model\u001b[1;34m(model, data_loader, loss_fn, accuracy_fn)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;66;03m# Make predictions with the model\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;66;03m# Accumulate the loss and accuracy values per batch\u001b[39;00m\n\u001b[0;32m     25\u001b[0m         loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y)\n",
      "File \u001b[1;32md:\\Code\\AI\\PyTorch_Tutorial\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Code\\AI\\PyTorch_Tutorial\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[31], line 14\u001b[0m, in \u001b[0;36mFashionMNISTModelV1.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Code\\AI\\PyTorch_Tutorial\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Code\\AI\\PyTorch_Tutorial\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Code\\AI\\PyTorch_Tutorial\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:244\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 244\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32md:\\Code\\AI\\PyTorch_Tutorial\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Code\\AI\\PyTorch_Tutorial\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Code\\AI\\PyTorch_Tutorial\\venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but got mat1 is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Note: This will error due to `eval_model()` not using device agnostic code \n",
    "model_1_results = eval_model(model=model_1, \n",
    "    data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn, \n",
    "    accuracy_fn=accuracy_fn) \n",
    "model_1_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5fbbf490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV1',\n",
       " 'model_loss': 0.22198039293289185,\n",
       " 'model_acc': 93.58027156549521}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move values to device\n",
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module, \n",
    "               data_loader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               accuracy_fn, \n",
    "               device: torch.device = device):\n",
    "    \"\"\"Evaluates a given model on a given dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
    "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
    "        loss_fn (torch.nn.Module): The loss function of model.\n",
    "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
    "        device (str, optional): Target device to compute on. Defaults to device.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Results of model making predictions on data_loader.\n",
    "    \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Send data to the target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "        \n",
    "        # Scale loss and acc\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "\n",
    "# Calculate model 1 results with device-agnostic code \n",
    "model_1_results = eval_model(model=model_1, data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn, accuracy_fn=accuracy_fn,\n",
    "    device=device\n",
    ")\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "696b74bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV0',\n",
       " 'model_loss': 0.3229216933250427,\n",
       " 'model_acc': 90.85463258785943}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check baseline results\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50640d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModelV2(\n",
       "  (block_1): Sequential(\n",
       "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block_2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a convolutional neural network \n",
    "class FashionMNISTModelV2(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture copying TinyVGG from: \n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3, # how big is the square that's going over the image?\n",
    "                      stride=1, # default\n",
    "                      padding=1),# options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2) # default stride value is same as kernel_size\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # Where did this in_features shape come from? \n",
    "            # It's because each layer of our network compresses and changes the shape of our input data.\n",
    "            nn.Linear(in_features=hidden_units*7*7, \n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.block_1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.block_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_2 = FashionMNISTModelV2(input_shape=1, \n",
    "    hidden_units=10, \n",
    "    output_shape=len(class_names)).to(device)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96fc9eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([32, 3, 64, 64]) -> [batch_size, color_channels, height, width]\n",
      "Single image shape: torch.Size([3, 64, 64]) -> [color_channels, height, width]\n",
      "Single image pixel values:\n",
      "tensor([[[ 1.9269,  1.4873,  0.9007,  ...,  1.8446, -1.1845,  1.3835],\n",
      "         [ 1.4451,  0.8564,  2.2181,  ...,  0.3399,  0.7200,  0.4114],\n",
      "         [ 1.9312,  1.0119, -1.4364,  ..., -0.5558,  0.7043,  0.7099],\n",
      "         ...,\n",
      "         [-0.5610, -0.4830,  0.4770,  ..., -0.2713, -0.9537, -0.6737],\n",
      "         [ 0.3076, -0.1277,  0.0366,  ..., -2.0060,  0.2824, -0.8111],\n",
      "         [-1.5486,  0.0485, -0.7712,  ..., -0.1403,  0.9416, -0.0118]],\n",
      "\n",
      "        [[-0.5197,  1.8524,  1.8365,  ...,  0.8935, -1.5114, -0.8515],\n",
      "         [ 2.0818,  1.0677, -1.4277,  ...,  1.6612, -2.6223, -0.4319],\n",
      "         [-0.1010, -0.4388, -1.9775,  ...,  0.2106,  0.2536, -0.7318],\n",
      "         ...,\n",
      "         [ 0.2779,  0.7342, -0.3736,  ..., -0.4601,  0.1815,  0.1850],\n",
      "         [ 0.7205, -0.2833,  0.0937,  ..., -0.1002, -2.3609,  2.2465],\n",
      "         [-1.3242, -0.1973,  0.2920,  ...,  0.5409,  0.6940,  1.8563]],\n",
      "\n",
      "        [[-0.7978,  1.0261,  1.1465,  ...,  1.2134,  0.9354, -0.0780],\n",
      "         [-1.4647, -1.9571,  0.1017,  ..., -1.9986, -0.7409,  0.7011],\n",
      "         [-1.3938,  0.8466, -1.7191,  ..., -1.1867,  0.1320,  0.3407],\n",
      "         ...,\n",
      "         [ 0.8206, -0.3745,  1.2499,  ..., -0.0676,  0.0385,  0.6335],\n",
      "         [-0.5589, -0.3393,  0.2347,  ...,  2.1181,  2.4569,  1.3083],\n",
      "         [-0.4092,  1.5199,  0.2401,  ..., -0.2558,  0.7870,  0.9924]]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Create sample batch of random numbers with same size as image batch\n",
    "images = torch.randn(size=(32, 3, 64, 64)) # [batch_size, color_channels, height, width]\n",
    "test_image = images[0] # get a single image for testing\n",
    "print(f\"Image batch shape: {images.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"Single image shape: {test_image.shape} -> [color_channels, height, width]\") \n",
    "print(f\"Single image pixel values:\\n{test_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3dcb273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5396,  0.0516,  0.6454,  ..., -0.3673,  0.8711,  0.4256],\n",
       "         [ 0.3662,  1.0114, -0.5997,  ...,  0.8983,  0.2809, -0.2741],\n",
       "         [ 1.2664, -1.4054,  0.3727,  ..., -0.3409,  1.2191, -0.0463],\n",
       "         ...,\n",
       "         [-0.1541,  0.5132, -0.3624,  ..., -0.2360, -0.4609, -0.0035],\n",
       "         [ 0.2981, -0.2432,  1.5012,  ..., -0.6289, -0.7283, -0.5767],\n",
       "         [-0.0386, -0.0781, -0.0388,  ...,  0.2842,  0.4228, -0.1802]],\n",
       "\n",
       "        [[-0.2840, -0.0319, -0.4455,  ..., -0.7956,  1.5599, -1.2449],\n",
       "         [ 0.2753, -0.1262, -0.6541,  ..., -0.2211,  0.1999, -0.8856],\n",
       "         [-0.5404, -1.5489,  0.0249,  ..., -0.5932, -1.0913, -0.3849],\n",
       "         ...,\n",
       "         [ 0.3870, -0.4064, -0.8236,  ...,  0.1734, -0.4330, -0.4951],\n",
       "         [-0.1984, -0.6386,  1.0263,  ..., -0.9401, -0.0585, -0.7833],\n",
       "         [-0.6306, -0.2052, -0.3694,  ..., -1.3248,  0.2456, -0.7134]],\n",
       "\n",
       "        [[ 0.4414,  0.5100,  0.4846,  ..., -0.8484,  0.2638,  1.1258],\n",
       "         [ 0.8117,  0.3191, -0.0157,  ...,  1.2686,  0.2319,  0.5003],\n",
       "         [ 0.3212,  0.0485, -0.2581,  ...,  0.2258,  0.2587, -0.8804],\n",
       "         ...,\n",
       "         [-0.1144, -0.1869,  0.0160,  ..., -0.8346,  0.0974,  0.8421],\n",
       "         [ 0.2941,  0.4417,  0.5866,  ..., -0.1224,  0.4814, -0.4799],\n",
       "         [ 0.6059, -0.0415, -0.2028,  ...,  0.1170,  0.2521, -0.4372]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.2560, -0.0477,  0.6380,  ...,  0.6436,  0.7553, -0.7055],\n",
       "         [ 1.5595, -0.2209, -0.9486,  ..., -0.4876,  0.7754,  0.0750],\n",
       "         [-0.0797,  0.2471,  1.1300,  ...,  0.1505,  0.2354,  0.9576],\n",
       "         ...,\n",
       "         [ 1.1065,  0.6839,  1.2183,  ...,  0.3015, -0.1910, -0.1902],\n",
       "         [-0.3486, -0.7173, -0.3582,  ...,  0.4917,  0.7219,  0.1513],\n",
       "         [ 0.0119,  0.1017,  0.7839,  ..., -0.3752, -0.8127, -0.1257]],\n",
       "\n",
       "        [[ 0.3841,  1.1322,  0.1620,  ...,  0.7010,  0.0109,  0.6058],\n",
       "         [ 0.1664,  0.1873,  1.5924,  ...,  0.3733,  0.9096, -0.5399],\n",
       "         [ 0.4094, -0.0861, -0.7935,  ..., -0.1285, -0.9932, -0.3013],\n",
       "         ...,\n",
       "         [ 0.2688, -0.5630, -1.1902,  ...,  0.4493,  0.5404, -0.0103],\n",
       "         [ 0.0535,  0.4411,  0.5313,  ...,  0.0148, -1.0056,  0.3759],\n",
       "         [ 0.3031, -0.1590, -0.1316,  ..., -0.5384, -0.4271, -0.4876]],\n",
       "\n",
       "        [[-1.1865, -0.7280, -1.2331,  ..., -0.9013, -0.0542, -1.5949],\n",
       "         [-0.6345, -0.5920,  0.5326,  ..., -1.0395, -0.7963, -0.0647],\n",
       "         [-0.1132,  0.5166,  0.2569,  ...,  0.5595, -1.6881,  0.9485],\n",
       "         ...,\n",
       "         [-0.0254, -0.2669,  0.1927,  ..., -0.2917,  0.1088, -0.4807],\n",
       "         [-0.2609, -0.2328,  0.1404,  ..., -0.1325, -0.8436, -0.7524],\n",
       "         [-1.1399, -0.1751, -0.8705,  ...,  0.1589,  0.3377,  0.3493]]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a convolutional layer with same dimensions as TinyVGG \n",
    "# (try changing any of the parameters and see what happens)\n",
    "conv_layer = nn.Conv2d(in_channels=3,\n",
    "                       out_channels=10,\n",
    "                       kernel_size=3,\n",
    "                       stride=1,\n",
    "                       padding=0) # also try using \"valid\" or \"same\" here \n",
    "\n",
    "# Pass the data through the convolutional layer\n",
    "conv_layer(test_image) # Note: If running PyTorch <1.11.0, this will error because of shape issues (nn.Conv.2d() expects a 4d tensor as input) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc787242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 64, 64])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add extra dimension to test image\n",
    "test_image.unsqueeze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb20e2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 62, 62])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass test image with extra dimension through conv_layer\n",
    "conv_layer(test_image.unsqueeze(dim=0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f713d9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 30, 30])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# Create a new conv_layer with different values (try setting these to whatever you like)\n",
    "conv_layer_2 = nn.Conv2d(in_channels=3, # same number of color channels as our input image\n",
    "                         out_channels=10,\n",
    "                         kernel_size=(5, 5), # kernel is usually a square so a tuple also works\n",
    "                         stride=2,\n",
    "                         padding=0)\n",
    "\n",
    "# Pass single image through new conv_layer_2 (this calls nn.Conv2d()'s forward() method on the input)\n",
    "conv_layer_2(test_image.unsqueeze(dim=0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e57127b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[[[ 0.0883,  0.0958, -0.0271,  0.1061, -0.0253],\n",
      "          [ 0.0233, -0.0562,  0.0678,  0.1018, -0.0847],\n",
      "          [ 0.1004,  0.0216,  0.0853,  0.0156,  0.0557],\n",
      "          [-0.0163,  0.0890,  0.0171, -0.0539,  0.0294],\n",
      "          [-0.0532, -0.0135, -0.0469,  0.0766, -0.0911]],\n",
      "\n",
      "         [[-0.0532, -0.0326, -0.0694,  0.0109, -0.1140],\n",
      "          [ 0.1043, -0.0981,  0.0891,  0.0192, -0.0375],\n",
      "          [ 0.0714,  0.0180,  0.0933,  0.0126, -0.0364],\n",
      "          [ 0.0310, -0.0313,  0.0486,  0.1031,  0.0667],\n",
      "          [-0.0505,  0.0667,  0.0207,  0.0586, -0.0704]],\n",
      "\n",
      "         [[-0.1143, -0.0446, -0.0886,  0.0947,  0.0333],\n",
      "          [ 0.0478,  0.0365, -0.0020,  0.0904, -0.0820],\n",
      "          [ 0.0073, -0.0788,  0.0356, -0.0398,  0.0354],\n",
      "          [-0.0241,  0.0958, -0.0684, -0.0689, -0.0689],\n",
      "          [ 0.1039,  0.0385,  0.1111, -0.0953, -0.1145]]],\n",
      "\n",
      "\n",
      "        [[[-0.0903, -0.0777,  0.0468,  0.0413,  0.0959],\n",
      "          [-0.0596, -0.0787,  0.0613, -0.0467,  0.0701],\n",
      "          [-0.0274,  0.0661, -0.0897, -0.0583,  0.0352],\n",
      "          [ 0.0244, -0.0294,  0.0688,  0.0785, -0.0837],\n",
      "          [-0.0616,  0.1057, -0.0390, -0.0409, -0.1117]],\n",
      "\n",
      "         [[-0.0661,  0.0288, -0.0152, -0.0838,  0.0027],\n",
      "          [-0.0789, -0.0980, -0.0636, -0.1011, -0.0735],\n",
      "          [ 0.1154,  0.0218,  0.0356, -0.1077, -0.0758],\n",
      "          [-0.0384,  0.0181, -0.1016, -0.0498, -0.0691],\n",
      "          [ 0.0003, -0.0430, -0.0080, -0.0782, -0.0793]],\n",
      "\n",
      "         [[-0.0674, -0.0395, -0.0911,  0.0968, -0.0229],\n",
      "          [ 0.0994,  0.0360, -0.0978,  0.0799, -0.0318],\n",
      "          [-0.0443, -0.0958, -0.1148,  0.0330, -0.0252],\n",
      "          [ 0.0450, -0.0948,  0.0857, -0.0848, -0.0199],\n",
      "          [ 0.0241,  0.0596,  0.0932,  0.1052, -0.0916]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0291, -0.0497, -0.0127, -0.0864,  0.1052],\n",
      "          [-0.0847,  0.0617,  0.0406,  0.0375, -0.0624],\n",
      "          [ 0.1050,  0.0254,  0.0149, -0.1018,  0.0485],\n",
      "          [-0.0173, -0.0529,  0.0992,  0.0257, -0.0639],\n",
      "          [-0.0584, -0.0055,  0.0645, -0.0295, -0.0659]],\n",
      "\n",
      "         [[-0.0395, -0.0863,  0.0412,  0.0894, -0.1087],\n",
      "          [ 0.0268,  0.0597,  0.0209, -0.0411,  0.0603],\n",
      "          [ 0.0607,  0.0432, -0.0203, -0.0306,  0.0124],\n",
      "          [-0.0204, -0.0344,  0.0738,  0.0992, -0.0114],\n",
      "          [-0.0259,  0.0017, -0.0069,  0.0278,  0.0324]],\n",
      "\n",
      "         [[-0.1049, -0.0426,  0.0972,  0.0450, -0.0057],\n",
      "          [-0.0696, -0.0706, -0.1034, -0.0376,  0.0390],\n",
      "          [ 0.0736,  0.0533, -0.1021, -0.0694, -0.0182],\n",
      "          [ 0.1117,  0.0167, -0.0299,  0.0478, -0.0440],\n",
      "          [-0.0747,  0.0843, -0.0525, -0.0231, -0.1149]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0773,  0.0875,  0.0421, -0.0805, -0.1140],\n",
      "          [-0.0938,  0.0861,  0.0554,  0.0972,  0.0605],\n",
      "          [ 0.0292, -0.0011, -0.0878, -0.0989, -0.1080],\n",
      "          [ 0.0473, -0.0567, -0.0232, -0.0665, -0.0210],\n",
      "          [-0.0813, -0.0754,  0.0383, -0.0343,  0.0713]],\n",
      "\n",
      "         [[-0.0370, -0.0847, -0.0204, -0.0560, -0.0353],\n",
      "          [-0.1099,  0.0646, -0.0804,  0.0580,  0.0524],\n",
      "          [ 0.0825, -0.0886,  0.0830, -0.0546,  0.0428],\n",
      "          [ 0.1084, -0.0163, -0.0009, -0.0266, -0.0964],\n",
      "          [ 0.0554, -0.1146,  0.0717,  0.0864,  0.1092]],\n",
      "\n",
      "         [[-0.0272, -0.0949,  0.0260,  0.0638, -0.1149],\n",
      "          [-0.0262, -0.0692, -0.0101, -0.0568, -0.0472],\n",
      "          [-0.0367, -0.1097,  0.0947,  0.0968, -0.0181],\n",
      "          [-0.0131, -0.0471, -0.1043, -0.1124,  0.0429],\n",
      "          [-0.0634, -0.0742, -0.0090, -0.0385, -0.0374]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0037, -0.0245, -0.0398, -0.0553, -0.0940],\n",
      "          [ 0.0968, -0.0462,  0.0306, -0.0401,  0.0094],\n",
      "          [ 0.1077,  0.0532, -0.1001,  0.0458,  0.1096],\n",
      "          [ 0.0304,  0.0774,  0.1138, -0.0177,  0.0240],\n",
      "          [-0.0803, -0.0238,  0.0855,  0.0592, -0.0731]],\n",
      "\n",
      "         [[-0.0926, -0.0789, -0.1140, -0.0891, -0.0286],\n",
      "          [ 0.0779,  0.0193, -0.0878, -0.0926,  0.0574],\n",
      "          [-0.0859, -0.0142,  0.0554, -0.0534, -0.0126],\n",
      "          [-0.0101, -0.0273, -0.0585, -0.1029, -0.0933],\n",
      "          [-0.0618,  0.1115, -0.0558, -0.0775,  0.0280]],\n",
      "\n",
      "         [[ 0.0318,  0.0633,  0.0878,  0.0643, -0.1145],\n",
      "          [ 0.0102,  0.0699, -0.0107, -0.0680,  0.1101],\n",
      "          [-0.0432, -0.0657, -0.1041,  0.0052,  0.0512],\n",
      "          [ 0.0256,  0.0228, -0.0876, -0.1078,  0.0020],\n",
      "          [ 0.1053,  0.0666, -0.0672, -0.0150, -0.0851]]],\n",
      "\n",
      "\n",
      "        [[[-0.0557,  0.0209,  0.0629,  0.0957, -0.1060],\n",
      "          [ 0.0772, -0.0814,  0.0432,  0.0977,  0.0016],\n",
      "          [ 0.1051, -0.0984, -0.0441,  0.0673, -0.0252],\n",
      "          [-0.0236, -0.0481,  0.0796,  0.0566,  0.0370],\n",
      "          [-0.0649, -0.0937,  0.0125,  0.0342, -0.0533]],\n",
      "\n",
      "         [[-0.0323,  0.0780,  0.0092,  0.0052, -0.0284],\n",
      "          [-0.1046, -0.1086, -0.0552, -0.0587,  0.0360],\n",
      "          [-0.0336, -0.0452,  0.1101,  0.0402,  0.0823],\n",
      "          [-0.0559, -0.0472,  0.0424, -0.0769, -0.0755],\n",
      "          [-0.0056, -0.0422, -0.0866,  0.0685,  0.0929]],\n",
      "\n",
      "         [[ 0.0187, -0.0201, -0.1070, -0.0421,  0.0294],\n",
      "          [ 0.0544, -0.0146, -0.0457,  0.0643, -0.0920],\n",
      "          [ 0.0730, -0.0448,  0.0018, -0.0228,  0.0140],\n",
      "          [-0.0349,  0.0840, -0.0030,  0.0901,  0.1110],\n",
      "          [-0.0563, -0.0842,  0.0926,  0.0905, -0.0882]]],\n",
      "\n",
      "\n",
      "        [[[-0.0089, -0.1139, -0.0945,  0.0223,  0.0307],\n",
      "          [ 0.0245, -0.0314,  0.1065,  0.0165, -0.0681],\n",
      "          [-0.0065,  0.0277,  0.0404, -0.0816,  0.0433],\n",
      "          [-0.0590, -0.0959, -0.0631,  0.1114,  0.0987],\n",
      "          [ 0.1034,  0.0678,  0.0872, -0.0155, -0.0635]],\n",
      "\n",
      "         [[ 0.0577, -0.0598, -0.0779, -0.0369,  0.0242],\n",
      "          [ 0.0594, -0.0448, -0.0680,  0.0156, -0.0681],\n",
      "          [-0.0752,  0.0602, -0.0194,  0.1055,  0.1123],\n",
      "          [ 0.0345,  0.0397,  0.0266,  0.0018, -0.0084],\n",
      "          [ 0.0016,  0.0431,  0.1074, -0.0299, -0.0488]],\n",
      "\n",
      "         [[-0.0280, -0.0558,  0.0196,  0.0862,  0.0903],\n",
      "          [ 0.0530, -0.0850, -0.0620, -0.0254, -0.0213],\n",
      "          [ 0.0095, -0.1060,  0.0359, -0.0881, -0.0731],\n",
      "          [-0.0960,  0.1006, -0.1093,  0.0871, -0.0039],\n",
      "          [-0.0134,  0.0722, -0.0107,  0.0724,  0.0835]]],\n",
      "\n",
      "\n",
      "        [[[-0.1003,  0.0444,  0.0218,  0.0248,  0.0169],\n",
      "          [ 0.0316, -0.0555, -0.0148,  0.1097,  0.0776],\n",
      "          [-0.0043, -0.1086,  0.0051, -0.0786,  0.0939],\n",
      "          [-0.0701, -0.0083, -0.0256,  0.0205,  0.1087],\n",
      "          [ 0.0110,  0.0669,  0.0896,  0.0932, -0.0399]],\n",
      "\n",
      "         [[-0.0258,  0.0556, -0.0315,  0.0541, -0.0252],\n",
      "          [-0.0783,  0.0470,  0.0177,  0.0515,  0.1147],\n",
      "          [ 0.0788,  0.1095,  0.0062, -0.0993, -0.0810],\n",
      "          [-0.0717, -0.1018, -0.0579, -0.1063, -0.1065],\n",
      "          [-0.0690, -0.1138, -0.0709,  0.0440,  0.0963]],\n",
      "\n",
      "         [[-0.0343, -0.0336,  0.0617, -0.0570, -0.0546],\n",
      "          [ 0.0711, -0.1006,  0.0141,  0.1020,  0.0198],\n",
      "          [ 0.0314, -0.0672, -0.0016,  0.0063,  0.0283],\n",
      "          [ 0.0449,  0.1003, -0.0881,  0.0035, -0.0577],\n",
      "          [-0.0913, -0.0092, -0.1016,  0.0806,  0.0134]]],\n",
      "\n",
      "\n",
      "        [[[-0.0622,  0.0603, -0.1093, -0.0447, -0.0225],\n",
      "          [-0.0981, -0.0734, -0.0188,  0.0876,  0.1115],\n",
      "          [ 0.0735, -0.0689, -0.0755,  0.1008,  0.0408],\n",
      "          [ 0.0031,  0.0156, -0.0928, -0.0386,  0.1112],\n",
      "          [-0.0285, -0.0058, -0.0959, -0.0646, -0.0024]],\n",
      "\n",
      "         [[-0.0717, -0.0143,  0.0470, -0.1130,  0.0343],\n",
      "          [-0.0763, -0.0564,  0.0443,  0.0918, -0.0316],\n",
      "          [-0.0474, -0.1044, -0.0595, -0.1011, -0.0264],\n",
      "          [ 0.0236, -0.1082,  0.1008,  0.0724, -0.1130],\n",
      "          [-0.0552,  0.0377, -0.0237, -0.0126, -0.0521]],\n",
      "\n",
      "         [[ 0.0927, -0.0645,  0.0958,  0.0075,  0.0232],\n",
      "          [ 0.0901, -0.0190, -0.0657, -0.0187,  0.0937],\n",
      "          [-0.0857,  0.0262, -0.1135,  0.0605,  0.0427],\n",
      "          [ 0.0049,  0.0496,  0.0001,  0.0639, -0.0914],\n",
      "          [-0.0170,  0.0512,  0.1150,  0.0588, -0.0840]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0888, -0.0257, -0.0247, -0.1050, -0.0182],\n",
      "          [ 0.0817,  0.0161, -0.0673,  0.0355, -0.0370],\n",
      "          [ 0.1054, -0.1002, -0.0365, -0.1115, -0.0455],\n",
      "          [ 0.0364,  0.1112,  0.0194,  0.1132,  0.0226],\n",
      "          [ 0.0667,  0.0926,  0.0965, -0.0646,  0.1062]],\n",
      "\n",
      "         [[ 0.0699, -0.0540, -0.0551, -0.0969,  0.0290],\n",
      "          [-0.0936,  0.0488,  0.0365, -0.1003,  0.0315],\n",
      "          [-0.0094,  0.0527,  0.0663, -0.1148,  0.1059],\n",
      "          [ 0.0968,  0.0459, -0.1055, -0.0412, -0.0335],\n",
      "          [-0.0297,  0.0651,  0.0420,  0.0915, -0.0432]],\n",
      "\n",
      "         [[ 0.0389,  0.0411, -0.0961, -0.1120, -0.0599],\n",
      "          [ 0.0790, -0.1087, -0.1005,  0.0647,  0.0623],\n",
      "          [ 0.0950, -0.0872, -0.0845,  0.0592,  0.1004],\n",
      "          [ 0.0691,  0.0181,  0.0381,  0.1096, -0.0745],\n",
      "          [-0.0524,  0.0808, -0.0790, -0.0637,  0.0843]]]])), ('bias', tensor([ 0.0364,  0.0373, -0.0489, -0.0016,  0.1057, -0.0693,  0.0009,  0.0549,\n",
      "        -0.0797,  0.1121]))])\n"
     ]
    }
   ],
   "source": [
    "# Check out the conv_layer_2 internal parameters\n",
    "print(conv_layer_2.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b0e4368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_layer_2 weight shape: \n",
      "torch.Size([10, 3, 5, 5]) -> [out_channels=10, in_channels=3, kernel_size=5, kernel_size=5]\n",
      "\n",
      "conv_layer_2 bias shape: \n",
      "torch.Size([10]) -> [out_channels=10]\n"
     ]
    }
   ],
   "source": [
    "# Get shapes of weight and bias tensors within conv_layer_2\n",
    "print(f\"conv_layer_2 weight shape: \\n{conv_layer_2.weight.shape} -> [out_channels=10, in_channels=3, kernel_size=5, kernel_size=5]\")\n",
    "print(f\"\\nconv_layer_2 bias shape: \\n{conv_layer_2.bias.shape} -> [out_channels=10]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac8c3012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image original shape: torch.Size([3, 64, 64])\n",
      "Test image with unsqueezed dimension: torch.Size([1, 3, 64, 64])\n",
      "Shape after going through conv_layer(): torch.Size([1, 10, 62, 62])\n",
      "Shape after going through conv_layer() and max_pool_layer(): torch.Size([1, 10, 31, 31])\n"
     ]
    }
   ],
   "source": [
    "# Print out original image shape without and with unsqueezed dimension\n",
    "print(f\"Test image original shape: {test_image.shape}\")\n",
    "print(f\"Test image with unsqueezed dimension: {test_image.unsqueeze(dim=0).shape}\")\n",
    "\n",
    "# Create a sample nn.MaxPoo2d() layer\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "# Pass data through just the conv_layer\n",
    "test_image_through_conv = conv_layer(test_image.unsqueeze(dim=0))\n",
    "print(f\"Shape after going through conv_layer(): {test_image_through_conv.shape}\")\n",
    "\n",
    "# Pass data through the max pool layer\n",
    "test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)\n",
    "print(f\"Shape after going through conv_layer() and max_pool_layer(): {test_image_through_conv_and_max_pool.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8711318a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor:\n",
      "tensor([[[[0.3367, 0.1288],\n",
      "          [0.2345, 0.2303]]]])\n",
      "Random tensor shape: torch.Size([1, 1, 2, 2])\n",
      "\n",
      "Max pool tensor:\n",
      "tensor([[[[0.3367]]]]) <- this is the maximum value from random_tensor\n",
      "Max pool tensor shape: torch.Size([1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# Create a random tensor with a similar number of dimensions to our images\n",
    "random_tensor = torch.randn(size=(1, 1, 2, 2))\n",
    "print(f\"Random tensor:\\n{random_tensor}\")\n",
    "print(f\"Random tensor shape: {random_tensor.shape}\")\n",
    "\n",
    "# Create a max pool layer\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2) # see what happens when you change the kernel_size value \n",
    "\n",
    "# Pass the random tensor through the max pool layer\n",
    "max_pool_tensor = max_pool_layer(random_tensor)\n",
    "print(f\"\\nMax pool tensor:\\n{max_pool_tensor} <- this is the maximum value from random_tensor\")\n",
    "print(f\"Max pool tensor shape: {max_pool_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d405e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_2.parameters(), \n",
    "                             lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "524624f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "---------\n",
      "Train loss: 0.26854 | Train accuracy: 91.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:09<00:18,  9.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.06483 | Test accuracy: 97.93%\n",
      "\n",
      "Epoch: 1\n",
      "---------\n",
      "Train loss: 0.06924 | Train accuracy: 97.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:18<00:09,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.05877 | Test accuracy: 98.16%\n",
      "\n",
      "Epoch: 2\n",
      "---------\n",
      "Train loss: 0.05347 | Train accuracy: 98.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.05371 | Test accuracy: 98.17%\n",
      "\n",
      "Train time on cuda: 27.057 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_model_2 = timer()\n",
    "\n",
    "# Train and test model \n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=train_dataloader, \n",
    "        model=model_2, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "    test_step(data_loader=test_dataloader,\n",
    "        model=model_2,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "train_time_end_model_2 = timer()\n",
    "total_train_time_model_2 = print_train_time(start=train_time_start_model_2,\n",
    "                                           end=train_time_end_model_2,\n",
    "                                           device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5055870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV2',\n",
       " 'model_loss': 0.053707342594861984,\n",
       " 'model_acc': 98.1729233226837}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get model_2 results \n",
    "model_2_results = eval_model(\n",
    "    model=model_2,\n",
    "    data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_fn\n",
    ")\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6b59960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_loss</th>\n",
       "      <th>model_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FashionMNISTModelV0</td>\n",
       "      <td>0.322922</td>\n",
       "      <td>90.854633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FashionMNISTModelV1</td>\n",
       "      <td>0.221980</td>\n",
       "      <td>93.580272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FashionMNISTModelV2</td>\n",
       "      <td>0.053707</td>\n",
       "      <td>98.172923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name  model_loss  model_acc\n",
       "0  FashionMNISTModelV0    0.322922  90.854633\n",
       "1  FashionMNISTModelV1    0.221980  93.580272\n",
       "2  FashionMNISTModelV2    0.053707  98.172923"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "compare_results = pd.DataFrame([model_0_results, model_1_results, model_2_results])\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "24bc03c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_loss</th>\n",
       "      <th>model_acc</th>\n",
       "      <th>training_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FashionMNISTModelV0</td>\n",
       "      <td>0.322922</td>\n",
       "      <td>90.854633</td>\n",
       "      <td>18.209627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FashionMNISTModelV1</td>\n",
       "      <td>0.221980</td>\n",
       "      <td>93.580272</td>\n",
       "      <td>24.914975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FashionMNISTModelV2</td>\n",
       "      <td>0.053707</td>\n",
       "      <td>98.172923</td>\n",
       "      <td>27.056822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name  model_loss  model_acc  training_time\n",
       "0  FashionMNISTModelV0    0.322922  90.854633      18.209627\n",
       "1  FashionMNISTModelV1    0.221980  93.580272      24.914975\n",
       "2  FashionMNISTModelV2    0.053707  98.172923      27.056822"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add training times to results comparison\n",
    "compare_results[\"training_time\"] = [total_train_time_model_0,\n",
    "                                    total_train_time_model_1,\n",
    "                                    total_train_time_model_2]\n",
    "compare_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4bab8bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model: torch.nn.Module, data: list, device: torch.device = device):\n",
    "    pred_probs = []\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for sample in data:\n",
    "            # Prepare sample\n",
    "            sample = torch.unsqueeze(sample, dim=0).to(device) # Add an extra dimension and send sample to device\n",
    "\n",
    "            # Forward pass (model outputs raw logit)\n",
    "            pred_logit = model(sample)\n",
    "\n",
    "            # Get prediction probability (logit -> prediction probability)\n",
    "            pred_prob = torch.softmax(pred_logit.squeeze(), dim=0) # note: perform softmax on the \"logits\" dimension, not \"batch\" dimension (in this case we have a batch size of 1, so can perform on dim=0)\n",
    "\n",
    "            # Get pred_prob off GPU for further calculations\n",
    "            pred_probs.append(pred_prob.cpu())\n",
    "            \n",
    "    # Stack the pred_probs to turn list into a tensor\n",
    "    return torch.stack(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93d22546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sample image shape: torch.Size([1, 28, 28])\n",
      "Test sample label: 2 (2 - two)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "for sample, label in random.sample(list(test_data), k=9):\n",
    "    test_samples.append(sample)\n",
    "    test_labels.append(label)\n",
    "\n",
    "# View the first test sample shape and label\n",
    "print(f\"Test sample image shape: {test_samples[0].shape}\\nTest sample label: {test_labels[0]} ({class_names[test_labels[0]]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c89eb3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0072e-09, 1.2450e-07, 1.0000e+00, 2.5282e-07, 2.6081e-17, 7.0077e-16,\n",
       "         1.7448e-14, 4.0350e-10, 1.4104e-06, 4.8147e-12],\n",
       "        [1.3227e-05, 9.9224e-01, 2.3152e-05, 1.5536e-06, 1.2437e-04, 9.5570e-04,\n",
       "         2.3053e-03, 2.5814e-06, 4.1010e-03, 2.3521e-04]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on test samples with model 2\n",
    "pred_probs= make_predictions(model=model_2, \n",
    "                             data=test_samples)\n",
    "\n",
    "# View first two prediction probabilities list\n",
    "pred_probs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3e95b80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 2, 4, 6, 6, 4, 9, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the prediction probabilities into prediction labels by taking the argmax()\n",
    "pred_classes = pred_probs.argmax(dim=1)\n",
    "pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0eddc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 1, 2, 4, 6, 6, 4, 9, 1], tensor([2, 1, 2, 4, 6, 6, 4, 9, 1]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are our predictions in the same form as our test labels? \n",
    "test_labels, pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6771e454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x900 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot predictions\n",
    "plt.figure(figsize=(9, 9))\n",
    "nrows = 3\n",
    "ncols = 3\n",
    "for i, sample in enumerate(test_samples):\n",
    "  # Create a subplot\n",
    "  plt.subplot(nrows, ncols, i+1)\n",
    "\n",
    "  # Plot the target image\n",
    "  plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
    "\n",
    "  # Find the prediction label (in text form, e.g. \"Sandal\")\n",
    "  pred_label = class_names[pred_classes[i]]\n",
    "\n",
    "  # Get the truth label (in text form, e.g. \"T-shirt\")\n",
    "  truth_label = class_names[test_labels[i]] \n",
    "\n",
    "  # Create the title text of the plot\n",
    "  title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
    "  \n",
    "  # Check for equality and change title colour accordingly\n",
    "  if pred_label == truth_label:\n",
    "      plt.title(title_text, fontsize=10, c=\"g\") # green text if correct\n",
    "  else:\n",
    "      plt.title(title_text, fontsize=10, c=\"r\") # red text if wrong\n",
    "  plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e7cddcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making predictions: 100%|██████████| 313/313 [00:01<00:00, 159.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. Make predictions with trained model\n",
    "y_preds = []\n",
    "model_2.eval()\n",
    "with torch.inference_mode():\n",
    "  for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
    "    # Send data and targets to target device\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    # Do the forward pass\n",
    "    y_logit = model_2(X)\n",
    "    # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
    "    y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1) # note: perform softmax on the \"logits\" dimension, not \"batch\" dimension (in this case we have a batch size of 32, so can perform on dim=1)\n",
    "    # Put predictions on CPU for evaluation\n",
    "    y_preds.append(y_pred.cpu())\n",
    "# Concatenate list of predictions into a tensor\n",
    "y_pred_tensor = torch.cat(y_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
